type("string")
type(12); type(12.3)
type(True)
type([1, "string", False])
type({
"key1": "value1",
"key2": 12.5
})
"string".capitalize(); "string".upper(); "string".lower()
"string".replace("i", "I")
len("string")
"Ardalan".capitalize()
"Ardalan".upper()
"Ardalan".lower()
len("Ardalan")
len(12)
len("12")
Dict = {"k1": 12, "k2": "str", True: 13.5, "k4": [1, False], 12: 24, "k5": {"k51": 1, "k52": True}}
Dict["k4"]
Dict["k5"]["k51"]
Dict["k6"] = "val1"
Dict
del(Dict["k4"])
Dict
Dict.keys()
Dict.values()
Dict.items()
len(Dict)
L = [2, "string", [True, "string2"], {"k1": 12, "k2": "str3"}]
L[0]; L[:2]; L[3]["k1"]; L[2][0]
L[1] = "str"
L
del(L[1])
L
L + [1,[2,True]]
len(L)
max([1,12,13.5,2])
L = [1, 12.5, "str", 14, [2.5, False]]
L.index(12.5)
L.reverse()
L
L.append("str2")
L
L.remove(14)
L
L1 = [1, True];
L2 = list(L1)
L2
L2[0] = False;
L1
L2
L1 = [1, 12.5];
L2 = [2, 13]
L1 + L2
L1/L2   # not supported
L1 > 1  # not supported
import numpy as np
L1 = np.array([1, 12.5]);
L2 = np.array([2, 13])
L1 + L2
(L1/L2) ** 2
L1 > 1
L1[L1 > 1]
L1_2_1 = np.array([L1, L2, L1])
L1_2_1
[L1, L2, L1]
type(L1)
type(L1_2_1)
L1.shape
L1_2_1.shape
L1_2_1[0][1]; L1_2_1[0, 1]; L1_2_1[0:3, 0]
L1_2_1
L3 = [1, 0, 12.5, -2, 1, 1, -5.1234]
np.mean(L3)
np.median(L3)
np.std(L3)
np.round(L3, 2)
np.sum(L3)
np.sort(L3)
np.var(L3)
np.quantile(L3, .95)
np.cumsum(L3)
np.random.rand()
np.random.normal(0, 1, 3)
np.random.seed(2021)
np.random.normal(0, 1, 3)
np.random.seed(2021)
np.random.normal(0, 1, 3)
np.random.normal(0, 1, 3)
np.random.seed(2021)
np.random.normal(0, 1, 3)
np.column_stack([[L1, L2]]); [L1, L2]
L1
L2
np.logical_and(L1 >= 1, L2 > 1)
np.logical_or(L1 > 2, L2 > 2)
np.logical_not(L1 > 1)
L1 > L2
if (L1 > L2).any():
print("Yes")
else:
print("No")
# for
L1 > L2
range(1, 10)
for i in range(1, 10):
print(i)
for i in "HelLo":
print(i.lower())
for i in ["s1", "s2"]: # np.array(["st1", "st2"])
print(i + "dm")
enumerate(["st1", "st2"])
for ind, val  in enumerate(["st1", "st2"]):
print(str(ind) + "=" + "val")
for ind, val  in enumerate(["st1", "st2"]):
print(str(ind) + "=" + val)
for v in np.nditer(np.array([L1, L2])): # +2Darray
print(v)
np.nditer(np.array([L1, L2]))
for k, v in {"k1": 12, "k2": True}.items():
print(k + ": " + str(v))
import seaborn as sns
import pandas as pd
data = sns.load_dataset("penguins")
pd.set_option("display.max_columns", 4)
data.transpose()
pd.set_option("display.max_columns", 10**6)
data.transpose()
data.head()
data.head()
data.info()
data.describe()
data.dtypes
data.shape
data.columns
data.index
data.values
data.sort_values(['bill_depth_mm', 'bill_length_mm'],
ascending=[False, True])
data
data.bill_depth_mm # = data['bill_depth_mm']
type(data.bill_depth_mm)
data[['bill_depth_mm']]
data[['bill_depth_mm', 'species']]  # reorder column
fav_cols = ['species', 'sex']
data[fav_cols]
data.index
data[data.columns.difference(fav_cols)]
data.loc[:, 'bill_depth_mm']; data.loc[:, ['bill_depth_mm']]
data.loc[:, 'bill_depth_mm']
data.loc[:, ['bill_depth_mm']]
data.iloc[:, 3]
data.iloc[:, [1]]
data.iloc[:, 0:2]
data.dtypes == 'float64'
(data.dtypes == 'float64').values
فغحث(data.dtypes == 'float64')
type(data.dtypes == 'float64')
(data.dtypes == 'float64')[0]
(data.dtypes == 'float64')[1]
(data.dtypes == 'float64')[2]
(data.dtypes == 'float64').soecies
(data.dtypes == 'float64').species
data.dtypes
data
type(data)
type(data)
data.columns
data.columns
data.index
data.values
data.values[0]
data.values[0][0]
data.values[0, 0]
data.dtypes
data.dtypes
type(data.dtypes)
type(data)
data.dtypes == 'float64'
type(data.dtypes == 'float64')
np.array(data.dtypes == 'float64')
(data.dtypes == 'float64').columns
(data.dtypes == 'float64').key
(data.dtypes == 'float64').keys
(data.dtypes == 'float64').values
(data.dtypes == 'float64').sex
(data.dtypes == 'float64')['sex']
(data.dtypes == 'float64').loc[:, 'sex']
(data.dtypes == 'float64').loc[:, ['sex']]
(data.dtypes == 'float64').values
data.loc[:, "island"]
data.loc[ "island"]
data.loc[,"island"]
data.loc[0:3,"island"]
data.columns
data.dtypes == 'float64'
data.columns[data.dtypes == 'float64']
data2 = data.loc[:, num_data_cols]
data.columns[data.dtypes == 'float64']
num_data_cols = data.columns[data.dtypes == 'float64']
data2 = data.loc[:, num_data_cols]
data2
cols
data2[cols] > 100
col_logs = [(data2[cols] > 100).any() for cols in num_data_cols]
num_data_cols
col_logs
data
data.columns.str.contains('s')
data.columns[data.dtypes == 'float64']
data.columns[data.dtypes == 'float64']
(data2[cols] > 100).any() for cols in num_data_cols
col_logs = [(data2[cols] > 100).any() for cols in num_data_cols]
col_logs
num_data_cols = data.columns[data.dtypes == 'float64']
num_data_cols
data2 = data.loc[:, num_data_cols]
col_logs = [(data2[cols] > 100).any() for cols in num_data_cols]
data2.loc[:, col_logs]
num_data_cols
data
data.species.str.startswith('Ad')
data['species'].str.startswith('Ad')
data[['species']].str.startswith('Ad')
data['species'].str.startswith('Ad')
data.island
data.island.isin(['Torgersen', 'Dream'])
row_logs1 = data.bill_depth_mm > 15                  # numeric
row_logs2 = data.species.str.startswith('Ad')        # string
row_logs3 = data.island.isin(['Torgersen', 'Dream']) # categorical
row_logs2
row_logs1 & row_logs2
data.loc[row_logs, :]
data.loc[row_logs4, :]
row_logs4 = row_logs1 & row_logs2
data.loc[row_logs4, :]
data[row_logs1]
data.query("bill_length_mm >= 40 & sex == 'Male'")
data.bill_depth_mm > 15
data.nlargest(3, 'bill_length_mm')
data.nsmallest(3, 'bill_length_mm')
data["new"] = 2 # Add a new col
data
data["new3"] = 2 # Add a new col
data
min(data.bill_length_mm)
data["new2"] = data["new"] + data.bill_depth_mm + min(data.bill_length_mm)
data
data.dropna()
data
data_nonmiss = data.dropna()
data_nonmiss.groupby('sex')['bill_length_mm'].max()
summarise_data = data_nonmiss.groupby(['species', 'sex'])[['bill_length_mm']].agg([np.mean, np.max])
summarise_data
summarise_data.iloc[:, 3]
summarise_data = data_nonmiss.groupby(['species', 'sex'])[['bill_length_mm']].agg([np.mean, np.max])
summarise_data.iloc[:, 3]
summarise_data.iloc[:, 2]
summarise_data
summarise_data.shape
summarise_data.iloc[:, 1]
summarise_data.iloc[:, 0]
summarise_data.iloc[:, 1]
data_nonmiss.bill_depth_mm
data_nonmiss.bill_depth_mm.agg([np.min, np.mean, np.max])
data_nonmiss.pivot_table(values="bill_length_mm",
index= ["species"],
columns="sex",
aggfunc=np.mean,
margins=True)
data
data.drop_duplicates(subset=['new', 'new3'])
data
data.drop_duplicates(subset=['new', 'new2'])
data.drop_duplicates(subset=['new', 'new'])
data.drop_duplicates(subset=['new', 'new3'])
data
data.sex.unique()
data.sex.unique().shape()
data.sex.unique()
data.sex.unique()[0]
data.sex.value_counts(normalize=True, dropna=False)
data.sex.value_counts(normalize=False, dropna=False)   # dplyr::count()
data.sex.value_counts(normalize=True, dropna=False)   # dplyr::count()
data.sex.value_counts(normalize=True, dropna=True)   # dplyr::count()
data.isna()              # missing = NaN
data.isna().any()        # if there is at least one missing values
data.isna().sum()        # num of missing values for each column
data.dropna()            # at least one row value is zerp
data.dropna(how = 'all') # all row values are na
data.dropna(axis = 'columns') # columns with at least one na values
data.fillna("Missing")
data.index
data
data.set_index('species')
data.set_index(['species', 'sex'])
data.index
data = data.set_index('species')
data = data.set_index(['species', 'sex'])
data
data.sort_index(ascending=[False, True])
۲
2
setwd("~/Python")
reticulate::repl_python()
reticulate::repl_python()
